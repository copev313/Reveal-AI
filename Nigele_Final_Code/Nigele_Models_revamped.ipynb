{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7H-_2QiRNt1"
   },
   "source": [
    "## Multi Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive first\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link to drive with images for reference\n",
    "# https://drive.google.com/drive/folders/1WIZB_ZLItOE0XkjQg2FsLZIuoSnIcYQp\n",
    "!apt-get install -y p7zip-full\n",
    "DRIVE_ZIP_PATH_1 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K First Sample/test.7z'\n",
    "DRIVE_ZIP_PATH_2 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K First Sample/train.7z'\n",
    "DRIVE_ZIP_PATH_3 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K First Sample/validation.7z'\n",
    "\n",
    "\n",
    "# # Local temporary disk destination\n",
    "LOCAL_DESTINATION = '/content/'\n",
    "\n",
    "# # Execute the copy command\n",
    "\n",
    "!cp \"{DRIVE_ZIP_PATH_1}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_2}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_3}\" \"{LOCAL_DESTINATION}\"\n",
    "\n",
    "print(f\" Copied data to local Colab disk.\")\n",
    "# # Path to the ZIP file on the local disk\n",
    "\n",
    "LOCAL_ZIP_PATH_1 = '/content/test.7z'\n",
    "LOCAL_ZIP_PATH_2 = '/content/train.7z'\n",
    "LOCAL_ZIP_PATH_3 = '/content/validation.7z'\n",
    "\n",
    "# # Execute the unzip command\n",
    "# # -q: quiet (less terminal output)\n",
    "# # -d /content/: extract contents to the /content/ directory\n",
    "\n",
    "!7z x \"{LOCAL_ZIP_PATH_1}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_2}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_3}\" -o/content/\n",
    "print(\" Unzipping complete! Your data is now fast to access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install transformers timm ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u have to get ride of the empty files or the model wont run\n",
    "import os\n",
    "\n",
    "folders = [\n",
    "    \"/content/train/ai\",\n",
    "    \"/content/train/real\",\n",
    "    \"/content/test/ai\",\n",
    "    \"/content/test/real\",\n",
    "    \"/content/validation/ai\",\n",
    "    \"/content/validation/real\"\n",
    "]\n",
    "\n",
    "count_removed = 0\n",
    "for folder in folders:\n",
    "  for f in os.listdir(folder):\n",
    "    path = os.path.join(folder, f)\n",
    "    if os.path.isfile(path) and f.lower().endswith(('.jpg', '.jpeg')):\n",
    "        if os.path.getsize(path) == 0:\n",
    "            os.remove(path)\n",
    "            count_removed += 1\n",
    "            # print(f\"Deleted empty file: {path}\")\n",
    "print('Count of deleted files : ', count_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys,torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torchvision.models import shufflenet_v2_x1_0, ShuffleNet_V2_X1_0_Weights\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_check = {}\n",
    "# verify that the images are the same size or not\n",
    "# print(os.listdir('1_fake')[0:10])\n",
    "for img in os.listdir('/content/train/ai'):\n",
    "    if '.ipynb_checkpoints' == img:\n",
    "        continue\n",
    "    images=Image.open('/content/train/ai/'+img)\n",
    "    # print(images.size)\n",
    "    if images.size in size_check:\n",
    "        size_check[images.size] += 1\n",
    "    else:\n",
    "        size_check[images.size] = 1\n",
    "# sizes are not the same\n",
    "print(list(size_check.items())[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_path = \"/content/train\"\n",
    "test_path  = \"/content/validation\"\n",
    "\n",
    "train_data = datasets.ImageFolder(train_path, transform=transform)\n",
    "test_data  = datasets.ImageFolder(test_path,  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader  = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = train_data.classes\n",
    "num_classes = len(class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, epochs=10, model_name=\"model\"):\n",
    "    metrics = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    model.to(device)\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "\n",
    "        metrics[\"train_loss\"].append(epoch_train_loss)\n",
    "        metrics[\"train_acc\"].append(epoch_train_acc)\n",
    "        metrics[\"val_loss\"].append(epoch_val_loss)\n",
    "        metrics[\"val_acc\"].append(epoch_val_acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} \"\n",
    "            f\"Train Loss: {epoch_train_loss:.4f}  Train Acc: {epoch_train_acc:.4f} | \"\n",
    "            f\"Val Loss: {epoch_val_loss:.4f}  Val Acc: {epoch_val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "\n",
    "\n",
    "    plot(model_name, metrics, epochs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(model_name, metrics, epochs):\n",
    "\n",
    "    x = range(1, epochs + 1)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(x, metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(x, metrics[\"val_loss\"],   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{model_name} Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{model_name}_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(x, metrics[\"train_acc\"], label=\"Train Accuracy\")\n",
    "    plt.plot(x, metrics[\"val_acc\"],   label=\"Val Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{model_name} Accuracy Curve\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{model_name}_accuracy.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, model_name=\"model\"):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "            trues.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    prec = precision_score(trues, preds, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(trues, preds, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(trues, preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "\n",
    "    print(\"Accuracy :\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall   :\", rec)\n",
    "    print(\"F1 Score :\", f1)\n",
    "\n",
    "    return acc, prec, rec, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"convnext_tiny\", pretrained=True, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "convnext_model = train(model, criterion, optimizer, train_loader, val_loader, epochs=10, model_name=\"convnext_tiny\")\n",
    "evaluate(convnext_model, model_name=\"ConvNeXt Tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = timm.create_model(\"vit_large_patch14_224\", pretrained=False, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "vit_model = train(model, criterion, optimizer, train_loader, val_loader, epochs=10, model_name=\"vit\")\n",
    "evaluate(vit_model, model_name=\"Vision Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = timm.create_model(\"resnet50\", pretrained=True, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "resnet_model = train(model, criterion, optimizer, train_loader, val_loader, epochs=10,model_name=\"resnet50\")\n",
    "evaluate(resnet_model, model_name=\"ResNet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(1024, 2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "shuffle_model = train(model, criterion, optimizer, train_loader, val_loader, epochs=10, model_name=\"shufflenetv2\")\n",
    "evaluate(shuffle_model, model_name=\"ShuffleNetV2\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
