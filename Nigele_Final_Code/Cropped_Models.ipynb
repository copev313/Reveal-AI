{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH62x4OVM7nS"
   },
   "source": [
    "## Cropped Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# mount drive first\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "p7zip-full is already the newest version (16.02+dfsg-8).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
      " Copied data to local Colab disk.\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,12 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (50657),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 341717408 bytes (326 MiB)\n",
      "\n",
      "Extracting archive: /content/test.7z\n",
      "--\n",
      "Path = /content/test.7z\n",
      "Type = 7z\n",
      "Physical Size = 341717408\n",
      "Headers Size = 95582\n",
      "Method = LZMA2:24 BCJ\n",
      "Solid = +\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b\n",
      "Would you like to replace the existing file:\n",
      "  Path:     /content/DL_Temp/test/ai/000_biggan_00130_crop1.jpg\n",
      "  Size:     4497 bytes (5 KiB)\n",
      "  Modified: 2025-11-20 14:16:59\n",
      "with the file from archive:\n",
      "  Path:     DL_Temp/test/ai/000_biggan_00130_crop1.jpg\n",
      "  Size:     4497 bytes (5 KiB)\n",
      "  Modified: 2025-11-20 14:16:59\n",
      "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? \n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,12 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (50657),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 1588469166 bytes (1515 MiB)\n",
      "\n",
      "Extracting archive: /content/train.7z\n",
      "--\n",
      "Path = /content/train.7z\n",
      "Type = 7z\n",
      "Physical Size = 1588469166\n",
      "Headers Size = 428410\n",
      "Method = LZMA2:24 BCJ\n",
      "Solid = +\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b\n",
      "Archives with Errors: 1\n",
      "\n",
      "\n",
      "\n",
      "Break signaled\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,12 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (50657),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 349809481 bytes (334 MiB)\n",
      "\n",
      "Extracting archive: /content/validation.7z\n",
      "--\n",
      "Path = /content/validation.7z\n",
      "Type = 7z\n",
      "Physical Size = 349809481\n",
      "Headers Size = 96957\n",
      "Method = LZMA2:24 BCJ\n",
      "Solid = +\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b\n",
      "Would you like to replace the existing file:\n",
      "  Path:     /content/DL_Temp/validation/ai/001_biggan_00171_crop1.jpg\n",
      "  Size:     2495 bytes (3 KiB)\n",
      "  Modified: 2025-11-20 14:17:42\n",
      "with the file from archive:\n",
      "  Path:     DL_Temp/validation/ai/001_biggan_00171_crop1.jpg\n",
      "  Size:     2495 bytes (3 KiB)\n",
      "  Modified: 2025-11-20 14:17:42\n",
      "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit?  Unzipping complete! Your data is now fast to access.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Link to drive with images for reference\n",
    "# https://drive.google.com/drive/folders/1WIZB_ZLItOE0XkjQg2FsLZIuoSnIcYQp\n",
    "!apt-get install -y p7zip-full\n",
    "DRIVE_ZIP_PATH_1 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Cropped/test.7z'\n",
    "DRIVE_ZIP_PATH_2 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Cropped/train.7z'\n",
    "DRIVE_ZIP_PATH_3 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Cropped/validation.7z'\n",
    "\n",
    "\n",
    "# # Local temporary disk destination\n",
    "LOCAL_DESTINATION = '/content/'\n",
    "\n",
    "# # Execute the copy command\n",
    "\n",
    "!cp \"{DRIVE_ZIP_PATH_1}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_2}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_3}\" \"{LOCAL_DESTINATION}\"\n",
    "\n",
    "print(f\" Copied data to local Colab disk.\")\n",
    "# # Path to the ZIP file on the local disk\n",
    "\n",
    "LOCAL_ZIP_PATH_1 = '/content/test.7z'\n",
    "LOCAL_ZIP_PATH_2 = '/content/train.7z'\n",
    "LOCAL_ZIP_PATH_3 = '/content/validation.7z'\n",
    "\n",
    "# # Execute the unzip command\n",
    "# # -q: quiet (less terminal output)\n",
    "# # -d /content/: extract contents to the /content/ directory\n",
    "\n",
    "!7z x \"{LOCAL_ZIP_PATH_1}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_2}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_3}\" -o/content/\n",
    "print(\" Unzipping complete! Your data is now fast to access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install transformers timm ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of deleted files :  0\n"
     ]
    }
   ],
   "source": [
    "# u have to get ride of the empty files or the model wont run\n",
    "import os\n",
    "\n",
    "folders = [\n",
    "    \"/content/DL_Temp/train/ai\",\n",
    "    \"/content/DL_Temp/train/real\",\n",
    "    \"/content/DL_Temp/test/ai\",\n",
    "    \"/content/DL_Temp/test/real\",\n",
    "    \"/content/DL_Temp/validation/ai\",\n",
    "    \"/content/DL_Temp/validation/real\"\n",
    "]\n",
    "\n",
    "count_removed = 0\n",
    "for folder in folders:\n",
    "  for f in os.listdir(folder):\n",
    "    path = os.path.join(folder, f)\n",
    "    if os.path.isfile(path) and f.lower().endswith(('.jpg', '.jpeg')):\n",
    "        if os.path.getsize(path) == 0:\n",
    "            os.remove(path)\n",
    "            count_removed += 1\n",
    "            # print(f\"Deleted empty file: {path}\")\n",
    "print('Count of deleted files : ', count_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys,torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torchvision.models import shufflenet_v2_x1_0, ShuffleNet_V2_X1_0_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((69, 93), 3), ((391, 320), 1), ((107, 110), 1), ((176, 141), 1), ((187, 215), 2), ((154, 200), 1), ((85, 110), 2), ((202, 221), 3), ((280, 289), 1), ((351, 395), 2)]\n"
     ]
    }
   ],
   "source": [
    "size_check = {}\n",
    "# verify that the images are the same size or not\n",
    "# print(os.listdir('1_fake')[0:10])\n",
    "for img in os.listdir('/content/DL_Temp/train/ai'):\n",
    "    if '.ipynb_checkpoints' == img:\n",
    "        continue\n",
    "    images=Image.open('/content/DL_Temp/train/ai/'+img)\n",
    "    # print(images.size)\n",
    "    if images.size in size_check:\n",
    "        size_check[images.size] += 1\n",
    "    else:\n",
    "        size_check[images.size] = 1\n",
    "# sizes are not the same\n",
    "print(list(size_check.items())[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 32\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "classes = 2\n",
    "save_weights = \"convnext_tiny_best.pth\"\n",
    "l_plot = \"loss_curve.png\"\n",
    "acc_plot = \"accuracy_curve.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['ai', 'real']\n",
      "Total images: 33550\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "tf_eval = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "train_dset = datasets.ImageFolder('/content/DL_Temp/train', transform=tf_train)\n",
    "val_dset   = datasets.ImageFolder('/content/DL_Temp/validation', transform=tf_eval)\n",
    "\n",
    "print(f\"Classes: {train_dset.classes}\")\n",
    "print(f\"Total images: {len(train_dset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=batch_sz, shuffle=True)\n",
    "val_loader = DataLoader(val_dset, batch_size=batch_sz, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready on device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model('convnext_tiny', pretrained=True, num_classes=2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "convnext_tiny = model.to(device)\n",
    "\n",
    "print(\"Model ready on device:\", device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(convnext_tiny.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall    = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1        = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return (running_loss / len(loader),correct / total,precision,recall,f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  Train Loss: 0.0386 | Train Acc: 0.9867\n",
      "  Val Loss:   0.2035 | Val Acc: 0.9390\n",
      "  Precision:  0.9756 | Recall: 0.9004 | F1: 0.9365\n",
      "------------------------------------------------------------\n",
      "Best model saved to: vit_model_best.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 0.0382 | Train Acc: 0.9857\n",
      "  Val Loss:   0.1820 | Val Acc: 0.9415\n",
      "  Precision:  0.9203 | Recall: 0.9666 | F1: 0.9429\n",
      "------------------------------------------------------------\n",
      "Best model saved to: vit_model_best.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 0.0354 | Train Acc: 0.9876\n",
      "  Val Loss:   0.1683 | Val Acc: 0.9473\n",
      "  Precision:  0.9512 | Recall: 0.9430 | F1: 0.9471\n",
      "------------------------------------------------------------\n",
      "Best model saved to: vit_model_best.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 0.0340 | Train Acc: 0.9874\n",
      "  Val Loss:   0.1925 | Val Acc: 0.9405\n",
      "  Precision:  0.9415 | Recall: 0.9394 | F1: 0.9404\n",
      "------------------------------------------------------------\n",
      "Epoch 5/10\n",
      "  Train Loss: 0.0321 | Train Acc: 0.9880\n",
      "  Val Loss:   0.2211 | Val Acc: 0.9323\n",
      "  Precision:  0.9068 | Recall: 0.9636 | F1: 0.9343\n",
      "------------------------------------------------------------\n",
      "Epoch 6/10\n",
      "  Train Loss: 0.0317 | Train Acc: 0.9890\n",
      "  Val Loss:   0.2381 | Val Acc: 0.9187\n",
      "  Precision:  0.9197 | Recall: 0.9174 | F1: 0.9185\n",
      "------------------------------------------------------------\n",
      "Epoch 7/10\n",
      "  Train Loss: 0.0299 | Train Acc: 0.9889\n",
      "  Val Loss:   0.2139 | Val Acc: 0.9294\n",
      "  Precision:  0.9216 | Recall: 0.9385 | F1: 0.9300\n",
      "------------------------------------------------------------\n",
      "Epoch 8/10\n",
      "  Train Loss: 0.0300 | Train Acc: 0.9894\n",
      "  Val Loss:   0.1913 | Val Acc: 0.9445\n",
      "  Precision:  0.9540 | Recall: 0.9341 | F1: 0.9439\n",
      "------------------------------------------------------------\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.0288 | Train Acc: 0.9898\n",
      "  Val Loss:   0.2752 | Val Acc: 0.9313\n",
      "  Precision:  0.9694 | Recall: 0.8907 | F1: 0.9284\n",
      "------------------------------------------------------------\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.0273 | Train Acc: 0.9907\n",
      "  Val Loss:   0.2119 | Val Acc: 0.9388\n",
      "  Precision:  0.9290 | Recall: 0.9502 | F1: 0.9395\n",
      "------------------------------------------------------------\n",
      "Saved loss plot: loss_curve.png\n",
      "Saved accuracy plot: accuracy_curve.png\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"train_loss\": [], \"val_loss\": [],\n",
    "    \"train_acc\": [],  \"val_acc\": [],\n",
    "    \"precision\": [],  \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(convnext_tiny, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, precision, recall, f1 = validate(convnext_tiny, val_loader, criterion)\n",
    "\n",
    "    metrics[\"train_loss\"].append(train_loss)\n",
    "    metrics[\"val_loss\"].append(val_loss)\n",
    "    metrics[\"train_acc\"].append(train_acc)\n",
    "    metrics[\"val_acc\"].append(val_acc)\n",
    "    metrics[\"precision\"].append(precision)\n",
    "    metrics[\"recall\"].append(recall)\n",
    "    metrics[\"f1\"].append(f1)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"  Precision:  {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(convnext_tiny.state_dict(), save_weights)\n",
    "        print(f\"Best model saved to: {save_weights}\")\n",
    "\n",
    "epochs_ = range(1, epochs + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(epochs_, metrics[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(f'convnext_{l_plot}')\n",
    "print(f\"Saved loss plot: {l_plot}\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(epochs_, metrics[\"val_acc\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(f'convnext_{acc_plot}')\n",
    "print(f\"Saved accuracy plot: {acc_plot}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1V52eSDzxq_T"
   },
   "source": [
    "## Model Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready on device: cuda\n",
      "Epoch 1/10\n",
      "  Train Loss: 0.9421 | Train Acc: 0.5191\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Best model saved to: vit_model_best.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 0.9432 | Train Acc: 0.5180\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Epoch 3/10\n",
      "  Train Loss: 0.9427 | Train Acc: 0.5186\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Epoch 4/10\n",
      "  Train Loss: 0.9427 | Train Acc: 0.5190\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Epoch 5/10\n",
      "  Train Loss: 0.9433 | Train Acc: 0.5183\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Epoch 6/10\n",
      "  Train Loss: 0.9433 | Train Acc: 0.5189\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Epoch 7/10\n",
      "  Train Loss: 0.9427 | Train Acc: 0.5186\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Epoch 8/10\n",
      "  Train Loss: 0.9426 | Train Acc: 0.5191\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.9429 | Train Acc: 0.5197\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.9429 | Train Acc: 0.5191\n",
      "  Val Loss:   0.9582 | Val Acc: 0.5205\n",
      "  Precision:  0.5338 | Recall: 0.3185 | F1: 0.3990\n",
      "------------------------------------------------------------\n",
      "Saved loss plot: loss_curve.png\n",
      "Saved accuracy plot: accuracy_curve.png\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "save_weights = \"vit_model_best.pth\"\n",
    "model = timm.create_model(\"vit_tiny_patch16_224\", pretrained=True, num_classes=2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vit_model = model.to(device)\n",
    "\n",
    "print(\"Model ready on device:\", device)\n",
    "metrics = {\n",
    "    \"train_loss\": [], \"val_loss\": [],\n",
    "    \"train_acc\": [],  \"val_acc\": [],\n",
    "    \"precision\": [],  \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(vit_model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, precision, recall, f1 = validate(vit_model, val_loader, criterion)\n",
    "\n",
    "    metrics[\"train_loss\"].append(train_loss)\n",
    "    metrics[\"val_loss\"].append(val_loss)\n",
    "    metrics[\"train_acc\"].append(train_acc)\n",
    "    metrics[\"val_acc\"].append(val_acc)\n",
    "    metrics[\"precision\"].append(precision)\n",
    "    metrics[\"recall\"].append(recall)\n",
    "    metrics[\"f1\"].append(f1)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"  Precision:  {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(vit_model.state_dict(), save_weights)\n",
    "        print(f\"Best model saved to: {save_weights}\")\n",
    "\n",
    "epochs_ = range(1, epochs + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(epochs_, metrics[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(l_plot)\n",
    "print(f\"Saved loss plot: {l_plot}\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(epochs_, metrics[\"val_acc\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(acc_plot)\n",
    "print(f\"Saved accuracy plot: {acc_plot}\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready on device: cuda\n",
      "Epoch 1/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4989\n",
      "  Val Loss:   0.6951 | Val Acc: 0.4985\n",
      "  Precision:  0.4991 | Recall: 0.9978 | F1: 0.6654\n",
      "------------------------------------------------------------\n",
      "Best model saved to: Shufflenet_model_best.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4989\n",
      "  Val Loss:   0.6950 | Val Acc: 0.4988\n",
      "  Precision:  0.4992 | Recall: 0.9978 | F1: 0.6655\n",
      "------------------------------------------------------------\n",
      "Best model saved to: Shufflenet_model_best.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4990\n",
      "  Val Loss:   0.6951 | Val Acc: 0.4988\n",
      "  Precision:  0.4992 | Recall: 0.9983 | F1: 0.6656\n",
      "------------------------------------------------------------\n",
      "Epoch 4/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4987\n",
      "  Val Loss:   0.6950 | Val Acc: 0.4988\n",
      "  Precision:  0.4992 | Recall: 0.9983 | F1: 0.6656\n",
      "------------------------------------------------------------\n",
      "Epoch 5/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4991\n",
      "  Val Loss:   0.6952 | Val Acc: 0.4987\n",
      "  Precision:  0.4992 | Recall: 0.9981 | F1: 0.6655\n",
      "------------------------------------------------------------\n",
      "Epoch 6/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4990\n",
      "  Val Loss:   0.6951 | Val Acc: 0.4990\n",
      "  Precision:  0.4993 | Recall: 0.9983 | F1: 0.6657\n",
      "------------------------------------------------------------\n",
      "Best model saved to: Shufflenet_model_best.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4988\n",
      "  Val Loss:   0.6950 | Val Acc: 0.4990\n",
      "  Precision:  0.4993 | Recall: 0.9986 | F1: 0.6657\n",
      "------------------------------------------------------------\n",
      "Epoch 8/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4991\n",
      "  Val Loss:   0.6951 | Val Acc: 0.4988\n",
      "  Precision:  0.4992 | Recall: 0.9983 | F1: 0.6656\n",
      "------------------------------------------------------------\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4990\n",
      "  Val Loss:   0.6951 | Val Acc: 0.4990\n",
      "  Precision:  0.4993 | Recall: 0.9986 | F1: 0.6657\n",
      "------------------------------------------------------------\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.6949 | Train Acc: 0.4990\n",
      "  Val Loss:   0.6951 | Val Acc: 0.4990\n",
      "  Precision:  0.4993 | Recall: 0.9981 | F1: 0.6656\n",
      "------------------------------------------------------------\n",
      "Saved loss plot: loss_curve.png\n",
      "Saved accuracy plot: accuracy_curve.png\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "save_weights = \"Shufflenet_model_best.pth\"\n",
    "model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(1024, 2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vit_model = model.to(device)\n",
    "\n",
    "print(\"Model ready on device:\", device)\n",
    "metrics = {\n",
    "    \"train_loss\": [], \"val_loss\": [],\n",
    "    \"train_acc\": [],  \"val_acc\": [],\n",
    "    \"precision\": [],  \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(vit_model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, precision, recall, f1 = validate(vit_model, val_loader, criterion)\n",
    "\n",
    "    metrics[\"train_loss\"].append(train_loss)\n",
    "    metrics[\"val_loss\"].append(val_loss)\n",
    "    metrics[\"train_acc\"].append(train_acc)\n",
    "    metrics[\"val_acc\"].append(val_acc)\n",
    "    metrics[\"precision\"].append(precision)\n",
    "    metrics[\"recall\"].append(recall)\n",
    "    metrics[\"f1\"].append(f1)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"  Precision:  {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(vit_model.state_dict(), save_weights)\n",
    "        print(f\"Best model saved to: {save_weights}\")\n",
    "\n",
    "epochs_ = range(1, epochs + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(epochs_, metrics[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(f'Shufflenet_{l_plot}')\n",
    "print(f\"Saved loss plot: {l_plot}\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(epochs_, metrics[\"val_acc\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(f'Shufflenet_{acc_plot}')\n",
    "print(f\"Saved accuracy plot: {acc_plot}\")\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
