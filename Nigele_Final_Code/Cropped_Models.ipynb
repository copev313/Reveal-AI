{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH62x4OVM7nS"
   },
   "source": [
    "## Cropped Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive first\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Link to drive with images for reference\n",
    "# https://drive.google.com/drive/folders/1WIZB_ZLItOE0XkjQg2FsLZIuoSnIcYQp\n",
    "!apt-get install -y p7zip-full\n",
    "DRIVE_ZIP_PATH_1 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Cropped/test.7z'\n",
    "DRIVE_ZIP_PATH_2 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Cropped/train.7z'\n",
    "DRIVE_ZIP_PATH_3 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Cropped/validation.7z'\n",
    "\n",
    "\n",
    "# # Local temporary disk destination\n",
    "LOCAL_DESTINATION = '/content/'\n",
    "\n",
    "# # Execute the copy command\n",
    "\n",
    "!cp \"{DRIVE_ZIP_PATH_1}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_2}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_3}\" \"{LOCAL_DESTINATION}\"\n",
    "\n",
    "print(f\" Copied data to local Colab disk.\")\n",
    "# # Path to the ZIP file on the local disk\n",
    "\n",
    "LOCAL_ZIP_PATH_1 = '/content/test.7z'\n",
    "LOCAL_ZIP_PATH_2 = '/content/train.7z'\n",
    "LOCAL_ZIP_PATH_3 = '/content/validation.7z'\n",
    "\n",
    "# # Execute the unzip command\n",
    "# # -q: quiet (less terminal output)\n",
    "# # -d /content/: extract contents to the /content/ directory\n",
    "\n",
    "!7z x \"{LOCAL_ZIP_PATH_1}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_2}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_3}\" -o/content/\n",
    "print(\" Unzipping complete! Your data is now fast to access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install transformers timm ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u have to get ride of the empty files or the model wont run\n",
    "import os\n",
    "\n",
    "folders = [\n",
    "    \"/content/DL_Temp/train/ai\",\n",
    "    \"/content/DL_Temp/train/real\",\n",
    "    \"/content/DL_Temp/test/ai\",\n",
    "    \"/content/DL_Temp/test/real\",\n",
    "    \"/content/DL_Temp/validation/ai\",\n",
    "    \"/content/DL_Temp/validation/real\"\n",
    "]\n",
    "\n",
    "count_removed = 0\n",
    "for folder in folders:\n",
    "  for f in os.listdir(folder):\n",
    "    path = os.path.join(folder, f)\n",
    "    if os.path.isfile(path) and f.lower().endswith(('.jpg', '.jpeg')):\n",
    "        if os.path.getsize(path) == 0:\n",
    "            os.remove(path)\n",
    "            count_removed += 1\n",
    "            # print(f\"Deleted empty file: {path}\")\n",
    "print('Count of deleted files : ', count_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys,torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torchvision.models import shufflenet_v2_x1_0, ShuffleNet_V2_X1_0_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_check = {}\n",
    "# verify that the images are the same size or not\n",
    "# print(os.listdir('1_fake')[0:10])\n",
    "for img in os.listdir('/content/DL_Temp/train/ai'):\n",
    "    if '.ipynb_checkpoints' == img:\n",
    "        continue\n",
    "    images=Image.open('/content/DL_Temp/train/ai/'+img)\n",
    "    # print(images.size)\n",
    "    if images.size in size_check:\n",
    "        size_check[images.size] += 1\n",
    "    else:\n",
    "        size_check[images.size] = 1\n",
    "# sizes are not the same\n",
    "print(list(size_check.items())[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 32\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "classes = 2\n",
    "save_weights = \"convnext_tiny_best.pth\"\n",
    "l_plot = \"loss_curve.png\"\n",
    "acc_plot = \"accuracy_curve.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "tf_eval = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "train_dset = datasets.ImageFolder('/content/DL_Temp/train', transform=tf_train)\n",
    "val_dset   = datasets.ImageFolder('/content/DL_Temp/validation', transform=tf_eval)\n",
    "\n",
    "print(f\"Classes: {train_dset.classes}\")\n",
    "print(f\"Total images: {len(train_dset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=batch_sz, shuffle=True)\n",
    "val_loader = DataLoader(val_dset, batch_size=batch_sz, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('convnext_tiny', pretrained=True, num_classes=2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "convnext_tiny = model.to(device)\n",
    "\n",
    "print(\"Model ready on device:\", device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(convnext_tiny.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall    = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1        = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return (running_loss / len(loader),correct / total,precision,recall,f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"train_loss\": [], \"val_loss\": [],\n",
    "    \"train_acc\": [],  \"val_acc\": [],\n",
    "    \"precision\": [],  \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(convnext_tiny, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, precision, recall, f1 = validate(convnext_tiny, val_loader, criterion)\n",
    "\n",
    "    metrics[\"train_loss\"].append(train_loss)\n",
    "    metrics[\"val_loss\"].append(val_loss)\n",
    "    metrics[\"train_acc\"].append(train_acc)\n",
    "    metrics[\"val_acc\"].append(val_acc)\n",
    "    metrics[\"precision\"].append(precision)\n",
    "    metrics[\"recall\"].append(recall)\n",
    "    metrics[\"f1\"].append(f1)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"  Precision:  {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(convnext_tiny.state_dict(), save_weights)\n",
    "        print(f\"Best model saved to: {save_weights}\")\n",
    "\n",
    "epochs_ = range(1, epochs + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(epochs_, metrics[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(f'convnext_{l_plot}')\n",
    "print(f\"Saved loss plot: {l_plot}\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(epochs_, metrics[\"val_acc\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(f'convnext_{acc_plot}')\n",
    "print(f\"Saved accuracy plot: {acc_plot}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1V52eSDzxq_T"
   },
   "source": [
    "## Model Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "save_weights = \"vit_model_best.pth\"\n",
    "model = timm.create_model(\"vit_tiny_patch16_224\", pretrained=True, num_classes=2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vit_model = model.to(device)\n",
    "\n",
    "print(\"Model ready on device:\", device)\n",
    "metrics = {\n",
    "    \"train_loss\": [], \"val_loss\": [],\n",
    "    \"train_acc\": [],  \"val_acc\": [],\n",
    "    \"precision\": [],  \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(vit_model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, precision, recall, f1 = validate(vit_model, val_loader, criterion)\n",
    "\n",
    "    metrics[\"train_loss\"].append(train_loss)\n",
    "    metrics[\"val_loss\"].append(val_loss)\n",
    "    metrics[\"train_acc\"].append(train_acc)\n",
    "    metrics[\"val_acc\"].append(val_acc)\n",
    "    metrics[\"precision\"].append(precision)\n",
    "    metrics[\"recall\"].append(recall)\n",
    "    metrics[\"f1\"].append(f1)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"  Precision:  {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(vit_model.state_dict(), save_weights)\n",
    "        print(f\"Best model saved to: {save_weights}\")\n",
    "\n",
    "epochs_ = range(1, epochs + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(epochs_, metrics[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(l_plot)\n",
    "print(f\"Saved loss plot: {l_plot}\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(epochs_, metrics[\"val_acc\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(acc_plot)\n",
    "print(f\"Saved accuracy plot: {acc_plot}\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "save_weights = \"Shufflenet_model_best.pth\"\n",
    "model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(1024, 2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vit_model = model.to(device)\n",
    "\n",
    "print(\"Model ready on device:\", device)\n",
    "metrics = {\n",
    "    \"train_loss\": [], \"val_loss\": [],\n",
    "    \"train_acc\": [],  \"val_acc\": [],\n",
    "    \"precision\": [],  \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(vit_model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, precision, recall, f1 = validate(vit_model, val_loader, criterion)\n",
    "\n",
    "    metrics[\"train_loss\"].append(train_loss)\n",
    "    metrics[\"val_loss\"].append(val_loss)\n",
    "    metrics[\"train_acc\"].append(train_acc)\n",
    "    metrics[\"val_acc\"].append(val_acc)\n",
    "    metrics[\"precision\"].append(precision)\n",
    "    metrics[\"recall\"].append(recall)\n",
    "    metrics[\"f1\"].append(f1)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"  Precision:  {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(vit_model.state_dict(), save_weights)\n",
    "        print(f\"Best model saved to: {save_weights}\")\n",
    "\n",
    "epochs_ = range(1, epochs + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(epochs_, metrics[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(f'Shufflenet_{l_plot}')\n",
    "print(f\"Saved loss plot: {l_plot}\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_, metrics[\"train_acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(epochs_, metrics[\"val_acc\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(f'Shufflenet_{acc_plot}')\n",
    "print(f\"Saved accuracy plot: {acc_plot}\")\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
