{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount drive first\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "p7zip-full is already the newest version (16.02+dfsg-8).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
      " Copied data to local Colab disk.\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,12 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (50657),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 714238854 bytes (682 MiB)\n",
      "\n",
      "Extracting archive: /content/test.7z\n",
      "--\n",
      "Path = /content/test.7z\n",
      "Type = 7z\n",
      "Physical Size = 714238854\n",
      "Headers Size = 103910\n",
      "Method = LZMA:23\n",
      "Solid = +\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b  0% - test/ai/000_biggan_00130.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 50 - test/ai/054_biggan_00066.jpg"
     ]
    }
   ],
   "source": [
    "# Link to drive with images for reference\n",
    "# https://drive.google.com/drive/folders/1WIZB_ZLItOE0XkjQg2FsLZIuoSnIcYQp\n",
    "!apt-get install -y p7zip-full\n",
    "DRIVE_ZIP_PATH_1 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K First Sample/test.7z'\n",
    "DRIVE_ZIP_PATH_2 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K First Sample/train.7z'\n",
    "DRIVE_ZIP_PATH_3 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K First Sample/validation.7z'\n",
    "\n",
    "\n",
    "# # Local temporary disk destination\n",
    "LOCAL_DESTINATION = '/content/'\n",
    "\n",
    "# # Execute the copy command\n",
    "\n",
    "!cp \"{DRIVE_ZIP_PATH_1}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_2}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_3}\" \"{LOCAL_DESTINATION}\"\n",
    "\n",
    "print(f\" Copied data to local Colab disk.\")\n",
    "# # Path to the ZIP file on the local disk\n",
    "\n",
    "LOCAL_ZIP_PATH_1 = '/content/test.7z'\n",
    "LOCAL_ZIP_PATH_2 = '/content/train.7z'\n",
    "LOCAL_ZIP_PATH_3 = '/content/validation.7z'\n",
    "\n",
    "# # Execute the unzip command\n",
    "# # -q: quiet (less terminal output)\n",
    "# # -d /content/: extract contents to the /content/ directory\n",
    "\n",
    "!7z x \"{LOCAL_ZIP_PATH_1}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_2}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_3}\" -o/content/\n",
    "print(\" Unzipping complete! Your data is now fast to access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install transformers timm ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u have to get ride of the empty files or the model wont run\n",
    "import os\n",
    "\n",
    "folders = [\n",
    "    \"/content/train/ai\",\n",
    "    \"/content/train/real\",\n",
    "    \"/content/test/ai\",\n",
    "    \"/content/test/real\",\n",
    "    \"/content/validation/ai\",\n",
    "    \"/content/validation/real\"\n",
    "]\n",
    "\n",
    "count_removed = 0\n",
    "for folder in folders:\n",
    "  for f in os.listdir(folder):\n",
    "    path = os.path.join(folder, f)\n",
    "    if os.path.isfile(path) and f.lower().endswith(('.jpg', '.jpeg')):\n",
    "        if os.path.getsize(path) == 0:\n",
    "            os.remove(path)\n",
    "            count_removed += 1\n",
    "            # print(f\"Deleted empty file: {path}\")\n",
    "print('Count of deleted files : ', count_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys,torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torchvision.models import shufflenet_v2_x1_0, ShuffleNet_V2_X1_0_Weights\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_path = \"/content/train\"\n",
    "val_path  = \"/content/validation\"\n",
    "test_path = \"/content/test\"\n",
    "\n",
    "train_data = datasets.ImageFolder(train_path, transform=transform)\n",
    "val_data  = datasets.ImageFolder(val_path,  transform=transform)\n",
    "test_data = datasets.ImageFolder(test_path,  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader  = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data,  batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = train_data.classes\n",
    "num_classes = len(class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_path, model_constructor, model_name=\"model\"):\n",
    "\n",
    "\n",
    "    model = model_constructor()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "            trues.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc  = accuracy_score(trues, preds)\n",
    "    prec = precision_score(trues, preds, average=\"weighted\", zero_division=0)\n",
    "    rec  = recall_score(trues, preds, average=\"weighted\", zero_division=0)\n",
    "    f1   = f1_score(trues, preds,     average=\"weighted\", zero_division=0)\n",
    "\n",
    "    print(f\"Test Accuracy : {acc:.4f}\")\n",
    "    print(f\"Test Precision: {prec:.4f}\")\n",
    "    print(f\"Test Recall   : {rec:.4f}\")\n",
    "    print(f\"Test F1 Score : {f1:.4f}\")\n",
    "\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(\n",
    "    model_path=\"/content/drive/MyDrive/resnet50.pth\",\n",
    "    model_constructor=lambda: timm.create_model(\"resnet50\", pretrained=False, num_classes=2),\n",
    "    model_name=\"ResNet50\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Standard photos model')\n",
    "test_model(\n",
    "    model_path=\"/content/drive/MyDrive/shufflenetv2.pth\",\n",
    "    model_constructor=lambda: shufflenet_v2_x1_0(weights=None, num_classes=2),\n",
    "    model_name=\"ShuffleNetV2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, epochs=10, model_name=\"model\"):\n",
    "    metrics = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    model.to(device)\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "\n",
    "        metrics[\"train_loss\"].append(epoch_train_loss)\n",
    "        metrics[\"train_acc\"].append(epoch_train_acc)\n",
    "        metrics[\"val_loss\"].append(epoch_val_loss)\n",
    "        metrics[\"val_acc\"].append(epoch_val_acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} \"\n",
    "            f\"Train Loss: {epoch_train_loss:.4f}  Train Acc: {epoch_train_acc:.4f} | \"\n",
    "            f\"Val Loss: {epoch_val_loss:.4f}  Val Acc: {epoch_val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), f\"{model_name}_cropped.pth\")\n",
    "\n",
    "\n",
    "    plot(model_name, metrics, epochs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(model_name, metrics, epochs):\n",
    "\n",
    "    x = range(1, epochs + 1)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(x, metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(x, metrics[\"val_loss\"],   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{model_name} Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{model_name}_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(x, metrics[\"train_acc\"], label=\"Train Accuracy\")\n",
    "    plt.plot(x, metrics[\"val_acc\"],   label=\"Val Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{model_name} Accuracy Curve\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{model_name}_accuracy.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, model_name=\"model\"):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "            trues.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    prec = precision_score(trues, preds, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(trues, preds, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(trues, preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "\n",
    "    print(\"Accuracy :\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall   :\", rec)\n",
    "    print(\"F1 Score :\", f1)\n",
    "\n",
    "    return acc, prec, rec, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Link to drive with images for reference\n",
    "# https://drive.google.com/drive/folders/1WIZB_ZLItOE0XkjQg2FsLZIuoSnIcYQp\n",
    "!apt-get install -y p7zip-full\n",
    "DRIVE_ZIP_PATH_1 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Scaled/test.7z'\n",
    "DRIVE_ZIP_PATH_2 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Scaled/train.7z'\n",
    "DRIVE_ZIP_PATH_3 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Scaled/validation.7z'\n",
    "\n",
    "\n",
    "# # Local temporary disk destination\n",
    "LOCAL_DESTINATION = '/content/'\n",
    "\n",
    "# # Execute the copy command\n",
    "\n",
    "!cp \"{DRIVE_ZIP_PATH_1}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_2}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_3}\" \"{LOCAL_DESTINATION}\"\n",
    "\n",
    "print(f\" Copied data to local Colab disk.\")\n",
    "# # Path to the ZIP file on the local disk\n",
    "\n",
    "LOCAL_ZIP_PATH_1 = '/content/test.7z'\n",
    "LOCAL_ZIP_PATH_2 = '/content/train.7z'\n",
    "LOCAL_ZIP_PATH_3 = '/content/validation.7z'\n",
    "\n",
    "# # Execute the unzip command\n",
    "# # -q: quiet (less terminal output)\n",
    "# # -d /content/: extract contents to the /content/ directory\n",
    "\n",
    "!7z x \"{LOCAL_ZIP_PATH_1}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_2}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_3}\" -o/content/\n",
    "print(\" Unzipping complete! Your data is now fast to access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_path = \"/content/DL_Temp/train\"\n",
    "val_path  = \"/content/DL_Temp/validation\"\n",
    "test_path = \"/content/DL_Temp/test\"\n",
    "\n",
    "train_data = datasets.ImageFolder(train_path, transform=transform)\n",
    "val_data  = datasets.ImageFolder(val_path,  transform=transform)\n",
    "test_data = datasets.ImageFolder(test_path,  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader  = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data,  batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = train_data.classes\n",
    "num_classes = len(class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scaled Model')\n",
    "torch.cuda.empty_cache()\n",
    "model = timm.create_model(\"resnet50\", pretrained=True, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "resnet_model = train(model, criterion, optimizer, train_loader, val_loader, epochs=10,model_name=\"resnet50\")\n",
    "evaluate(resnet_model, model_name=\"ResNet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scaled Model')\n",
    "test_model(\n",
    "    model_path=\"/content/resnet50.pth\",\n",
    "    model_constructor=lambda: timm.create_model(\"resnet50\", pretrained=False, num_classes=2),\n",
    "    model_name=\"ResNet50\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scaled Model')\n",
    "test_model(\n",
    "    model_path=\"/content/drive/MyDrive/Shufflenet_model_best_scaled.pth\",\n",
    "    model_constructor=lambda: shufflenet_v2_x1_0(weights=None, num_classes=2),\n",
    "    model_name=\"ShuffleNetV2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Link to drive with images for reference\n",
    "# https://drive.google.com/drive/folders/1WIZB_ZLItOE0XkjQg2FsLZIuoSnIcYQp\n",
    "!apt-get install -y p7zip-full\n",
    "DRIVE_ZIP_PATH_1 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Cropped/test.7z'\n",
    "DRIVE_ZIP_PATH_2 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Cropped/train.7z'\n",
    "DRIVE_ZIP_PATH_3 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/48K Cropped/validation.7z'\n",
    "\n",
    "\n",
    "# # Local temporary disk destination\n",
    "LOCAL_DESTINATION = '/content/'\n",
    "\n",
    "# # Execute the copy command\n",
    "\n",
    "!cp \"{DRIVE_ZIP_PATH_1}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_2}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_3}\" \"{LOCAL_DESTINATION}\"\n",
    "\n",
    "print(f\" Copied data to local Colab disk.\")\n",
    "# # Path to the ZIP file on the local disk\n",
    "\n",
    "LOCAL_ZIP_PATH_1 = '/content/test.7z'\n",
    "LOCAL_ZIP_PATH_2 = '/content/train.7z'\n",
    "LOCAL_ZIP_PATH_3 = '/content/validation.7z'\n",
    "\n",
    "# # Execute the unzip command\n",
    "# # -q: quiet (less terminal output)\n",
    "# # -d /content/: extract contents to the /content/ directory\n",
    "\n",
    "!7z x \"{LOCAL_ZIP_PATH_1}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_2}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_3}\" -o/content/\n",
    "print(\" Unzipping complete! Your data is now fast to access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cropped Model')\n",
    "torch.cuda.empty_cache()\n",
    "model = timm.create_model(\"resnet50\", pretrained=True, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "resnet_model = train(model, criterion, optimizer, train_loader, val_loader, epochs=10,model_name=\"resnet50\")\n",
    "evaluate(resnet_model, model_name=\"ResNet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cropped Model')\n",
    "test_model(\n",
    "    model_path=\"/content/drive/MyDrive/Shufflenet_model_best.pth\",\n",
    "    model_constructor=lambda: shufflenet_v2_x1_0(weights=None, num_classes=2),\n",
    "    model_name=\"ShuffleNetV2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
