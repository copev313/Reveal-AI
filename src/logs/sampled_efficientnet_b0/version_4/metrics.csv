epoch,lr-AdamW,step,train_acc,train_loss,val_acc,val_loss
,5e-05,0,,,,
0,,262,,,0.786518394947052,0.7227135896682739
0,,262,0.7125186324119568,1.2024867534637451,,
,5e-05,263,,,,
1,,525,,,0.8412786722183228,0.5006881952285767
1,,525,0.8716244697570801,0.37901145219802856,,
,5e-05,526,,,,
2,,788,,,0.8682418465614319,0.4211256802082062
2,,788,0.933681070804596,0.17857594788074493,,
,5e-05,789,,,,
3,,1051,,,0.8872828483581543,0.3747389018535614
3,,1051,0.9657824039459229,0.09347064048051834,,
,5e-05,1052,,,,
4,,1314,,,0.8925642967224121,0.36434513330459595
4,,1314,0.9814605116844177,0.05472645163536072,,
,5e-05,1315,,,,
5,,1577,,,0.8988186120986938,0.36180925369262695
5,,1577,0.9884649515151978,0.03563994914293289,,
,5e-05,1578,,,,
6,,1840,,,0.9031271934509277,0.34002503752708435
6,,1840,0.9933531880378723,0.024790789932012558,,
,5e-05,1841,,,,
7,,2103,,,0.9092425107955933,0.347308874130249
7,,2103,0.996363639831543,0.015260715037584305,,
,5e-05,2104,,,,
8,,2366,,,0.9071577191352844,0.3465721309185028
8,,2366,0.9967809319496155,0.01335400901734829,,
,5e-05,2367,,,,
9,,2629,,,0.9121612310409546,0.33864161372184753
9,,2629,0.9979732036590576,0.009135822765529156,,
,5e-05,2630,,,,
10,,2892,,,0.9141070246696472,0.34469813108444214
10,,2892,0.9985693097114563,0.007256017066538334,,
,5e-05,2893,,,,
11,,3155,,,0.9199444055557251,0.33477771282196045
11,,3155,0.9991356134414673,0.0058413539081811905,,
,5e-05,3156,,,,
12,,3418,,,0.9179986119270325,0.33806943893432617
12,,3418,0.9985693097114563,0.006338140461593866,,
,5e-05,3419,,,,
13,,3681,,,0.9179986119270325,0.33693134784698486
13,,3681,0.9987481236457825,0.00579651677981019,,
,5e-05,3682,,,,
14,,3944,,,0.9186935424804688,0.3406495749950409
14,,3944,0.9994038939476013,0.003506043925881386,,
