{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradCAM (Well, EigenCAM) for EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camme\\anaconda3\\envs\\DL_FinalProject\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\camme\\anaconda3\\envs\\DL_FinalProject\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Grad-CAM imports\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import cv2\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    ")\n",
    "\n",
    "from src.utils.helpers import load_config\n",
    "from src.training.dataset import ImageDataModule\n",
    "from src.models.classification_model import ImageClassifier\n",
    "\n",
    "from pytorch_grad_cam import EigenCAM, LayerCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to deal with ViT weirdness\n",
    "def vit_reshape_transform(tensor):\n",
    "    # Get patch grid size \n",
    "    h, w = net.backbone.patch_embed.grid_size \n",
    "\n",
    "    # Drop CLS token at position 0 \n",
    "    patch_tokens = tensor[:, 1:, :]  \n",
    "\n",
    "    # Reshape  \n",
    "    patch_tokens = patch_tokens.reshape(tensor.size(0), h, w, tensor.size(2))\n",
    "\n",
    "    # Permute to (B, C, H_p, W_p) for Grad-CAM\n",
    "    patch_tokens = patch_tokens.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "    return patch_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Found 50 corrupted files in ../../src/data/sampled/train.\n",
      "[NOTICE] Found 5 corrupted files in ../../src/data/sampled/validation.\n",
      "[NOTICE] Found 13 corrupted files in ../../src/data/sampled/test.\n",
      "Model device (first param): cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Can really use any model here - the important part is the test dataset in the model. \n",
    "config = load_config(\"sampled_efficientnet_b0.yaml\")\n",
    "config1 = config.copy()\n",
    "\n",
    "## ---- Data Set goes here:\n",
    "config1[\"data\"][\"test_path\"] = \"../../src/data/sampled/test\"\n",
    "data_module = ImageDataModule(config1)\n",
    "data_module.setup(\"test\")  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## ---- Model you want to test goes here:\n",
    "ckpt_path = \"../EfficientNet Standard/checkpoints/last.ckpt\"\n",
    "\n",
    "net = ImageClassifier.load_from_checkpoint(ckpt_path, config=config)\n",
    "net.to(device)\n",
    "net.eval()\n",
    "\n",
    "# Sanity check\n",
    "print(\"Model device (first param):\", next(net.parameters()).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop this section for each image you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Image Index to evaluate - See the file test_results_per_image.csv for possible results\n",
    "idx=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using image #5 -> ../../src/data/sampled/test\\ai\\004_sdv5_00095.jpg, label = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verify the image you want is right\n",
    "test_ds = data_module.test_dataset  \n",
    "img_tensor, label, path = test_ds[idx]\n",
    "print(f\"Using image #{idx} -> {path}, label = {label}\")\n",
    "\n",
    "# More weirdness for size\n",
    "input_tensor = img_tensor.unsqueeze(0).to(device)  \n",
    "\n",
    "# For overlay: load original image and resize to network input size\n",
    "pil_img = Image.open(path).convert(\"RGB\").resize((data_module.img_size, data_module.img_size))\n",
    "img_float = np.array(pil_img).astype(np.float32) / 255.0   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Grad Cam\n",
    "# I used EigenCAM for this for consistency with ViT\n",
    "\n",
    "## Option 1 - Standard\n",
    "#last_block = net.backbone.blocks[-1]\n",
    "#target_layers = [last_block]\n",
    "\n",
    "## Option 2 - Conv head\n",
    "target_layers = [net.backbone.conv_head]\n",
    "\n",
    "cam = EigenCAM(\n",
    "    model=net,\n",
    "    target_layers=target_layers, \n",
    "    # I don't need reshaping for this\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "# Do Predictions\n",
    "with torch.no_grad():\n",
    "    logits = net(input_tensor)\n",
    "    pred_class = int(logits.argmax(dim=1).item())\n",
    "print(\"Predicted class:\", pred_class) ## 0 = AI, 1 = Real\n",
    " \n",
    "grayscale_cam = cam(\n",
    "    input_tensor=input_tensor,\n",
    "    targets=[ClassifierOutputTarget(pred_class)],\n",
    ")[0, :]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Grad-CAM overlay to gradcam_efficientnet_5.jpg\n"
     ]
    }
   ],
   "source": [
    "# Make Heatmap and Save\n",
    "cam_image = show_cam_on_image(img_float, grayscale_cam, image_weight=0.6,  use_rgb=True)\n",
    "cam_bgr = cv2.cvtColor(cam_image, cv2.COLOR_RGB2BGR)\n",
    "out_path = \"gradcam_efficientnet_\"+str(idx)+\".jpg\"\n",
    "cv2.imwrite(out_path, cam_bgr)\n",
    "\n",
    "print(f\"Saved Grad-CAM overlay to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
