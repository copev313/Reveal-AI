{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giJH5uQ9UJih"
   },
   "source": [
    "## Reveal AI final project\n",
    "\n",
    "- *Will test multiple models in this notebook*\n",
    "- resnet50\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive first\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "!apt-get install -y p7zip-full\n",
    "DRIVE_ZIP_PATH_1 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/test.7z'\n",
    "DRIVE_ZIP_PATH_2 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/train.7z'\n",
    "DRIVE_ZIP_PATH_3 = '/content/drive/MyDrive/Colab Notebooks/RevealAI/validation.7z'\n",
    "\n",
    "\n",
    "# # Local temporary disk destination\n",
    "LOCAL_DESTINATION = '/content/'\n",
    "\n",
    "# # Execute the copy command\n",
    "\n",
    "!cp \"{DRIVE_ZIP_PATH_1}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_2}\" \"{LOCAL_DESTINATION}\"\n",
    "!cp \"{DRIVE_ZIP_PATH_3}\" \"{LOCAL_DESTINATION}\"\n",
    "\n",
    "print(f\" Copied data to local Colab disk.\")\n",
    "# # Path to the ZIP file on the local disk\n",
    "\n",
    "LOCAL_ZIP_PATH_1 = '/content/test.7z'\n",
    "LOCAL_ZIP_PATH_2 = '/content/train.7z'\n",
    "LOCAL_ZIP_PATH_3 = '/content/validation.7z'\n",
    "\n",
    "# # Execute the unzip command\n",
    "# # -q: quiet (less terminal output)\n",
    "# # -d /content/: extract contents to the /content/ directory\n",
    "\n",
    "!7z x \"{LOCAL_ZIP_PATH_1}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_2}\" -o/content/\n",
    "!7z x \"{LOCAL_ZIP_PATH_3}\" -o/content/\n",
    "print(\" Unzipping complete! Your data is now fast to access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install transformers timm ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u have to get ride of the empty files or the model wont run\n",
    "import os\n",
    "\n",
    "folders = [\n",
    "    \"/content/train/real\",\n",
    "    \"/content/test/ai\",\n",
    "    \"/content/test/real\",\n",
    "    \"/content/validation/ai\",\n",
    "    \"/content/validation/real\"\n",
    "]\n",
    "for folder in folders:\n",
    "  for f in os.listdir(folder):\n",
    "    path = os.path.join(folder, f)\n",
    "    if os.path.isfile(path) and f.lower().endswith(('.jpg', '.jpeg')):\n",
    "        if os.path.getsize(path) == 0:\n",
    "            os.remove(path)\n",
    "            print(f\"Deleted empty file: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys,torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import shufflenet_v2_x1_0, ShuffleNet_V2_X1_0_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_check = {}\n",
    "# verify that the images are the same size or not\n",
    "# print(os.listdir('1_fake')[0:10])\n",
    "for img in os.listdir('/content/train/ai'):\n",
    "    if '.ipynb_checkpoints' == img:\n",
    "        continue\n",
    "    images=Image.open('/content/train/ai/'+img)\n",
    "    # print(images.size)\n",
    "    if images.size in size_check:\n",
    "        size_check[images.size] += 1\n",
    "    else:\n",
    "        size_check[images.size] = 1\n",
    "# sizes are not the same\n",
    "print(list(size_check.items())[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images for convnext\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# Same transforms as your training\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "tf_eval = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder('/content/train', transform=tf_train)\n",
    "val_dataset   = datasets.ImageFolder('/content/validation', transform=tf_eval)\n",
    "test_dataset  = datasets.ImageFolder('/content/test', transform=tf_eval)\n",
    "\n",
    "print(f\"Classes: {train_dataset.classes}\")\n",
    "print(f\"Total images: {len(train_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIfPLESimwoI"
   },
   "source": [
    "## Model Convnext Tiny Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = timm.create_model('convnext_tiny', pretrained=True, num_classes=2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model ready on device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "for epoch in range(10):\n",
    "\n",
    "    # -------------------------\n",
    "    # TRAINING\n",
    "    # -------------------------\n",
    "    model.train()\n",
    "    train_total, train_correct, train_loss = 0, 0, 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "    # -------------------------\n",
    "    # VALIDATION\n",
    "    # -------------------------\n",
    "    model.eval()\n",
    "    val_total, val_correct, val_loss = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # -------------------------\n",
    "    # LOGGING\n",
    "    # -------------------------\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# pick random image from test/ai\n",
    "folder = \"/content/test/ai\"\n",
    "img_name = random.choice(os.listdir(folder))\n",
    "img_path = folder + \"/\" + img_name\n",
    "\n",
    "# same transform as eval\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "x = tf(img).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(x).argmax(1).item()\n",
    "\n",
    "label_names = train_dataset.classes  # ['ai', 'real']\n",
    "\n",
    "print(\"Predicted class:\", label_names[pred])\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {label_names[pred]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBBt8lMinx4o"
   },
   "source": [
    "## Model Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = timm.create_model('vit_large_patch14_224', pretrained=False, num_classes=2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model ready on device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    # -------------------------\n",
    "    # TRAINING\n",
    "    # -------------------------\n",
    "    model.train()\n",
    "    train_total, train_correct, train_loss = 0, 0, 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "    # -------------------------\n",
    "    # VALIDATION\n",
    "    # -------------------------\n",
    "    model.eval()\n",
    "    val_total, val_correct, val_loss = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # -------------------------\n",
    "    # LOGGING\n",
    "    # -------------------------\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# pick random image from test/ai\n",
    "folder = \"/content/test/ai\"\n",
    "img_name = random.choice(os.listdir(folder))\n",
    "img_path = folder + \"/\" + img_name\n",
    "\n",
    "# same transform as eval\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "x = tf(img).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(x).argmax(1).item()\n",
    "\n",
    "label_names = train_dataset.classes  # ['ai', 'real']\n",
    "\n",
    "print(\"Predicted class:\", label_names[pred])\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {label_names[pred]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIbdiQE0of-j"
   },
   "source": [
    "## Model Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model ready on device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    # -------------------------\n",
    "    # TRAINING\n",
    "    # -------------------------\n",
    "    model.train()\n",
    "    train_total, train_correct, train_loss = 0, 0, 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "    # -------------------------\n",
    "    # VALIDATION\n",
    "    # -------------------------\n",
    "    model.eval()\n",
    "    val_total, val_correct, val_loss = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # -------------------------\n",
    "    # LOGGING\n",
    "    # -------------------------\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# pick random image from test/ai\n",
    "folder = \"/content/test/ai\"\n",
    "img_name = random.choice(os.listdir(folder))\n",
    "img_path = folder + \"/\" + img_name\n",
    "\n",
    "# same transform as eval\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "x = tf(img).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(x).argmax(1).item()\n",
    "\n",
    "label_names = train_dataset.classes  # ['ai', 'real']\n",
    "\n",
    "print(\"Predicted class:\", label_names[pred])\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {label_names[pred]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm_ip_Sbo1k7"
   },
   "source": [
    "## Model ShuffleNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_classes = 2\n",
    "model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(1024, num_classes)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "print(\"Model ready on device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    # -------------------------\n",
    "    # TRAINING\n",
    "    # -------------------------\n",
    "    model.train()\n",
    "    train_total, train_correct, train_loss = 0, 0, 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "    # -------------------------\n",
    "    # VALIDATION\n",
    "    # -------------------------\n",
    "    model.eval()\n",
    "    val_total, val_correct, val_loss = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # -------------------------\n",
    "    # LOGGING\n",
    "    # -------------------------\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1)\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "print(\"Test Accuracy:\", 100 * test_correct / test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Folder to sample from\n",
    "folder = \"/content/test/ai\"\n",
    "img_name = random.choice(os.listdir(folder))\n",
    "img_path = folder + \"/\" + img_name\n",
    "\n",
    "# Same transform as eval\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load + preprocess\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "x = tf(img).unsqueeze(0).to(device)\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(x).argmax(1).item()\n",
    "\n",
    "label_names = train_dataset.classes  # ['ai', 'real']\n",
    "\n",
    "print(\"Random test image:\", img_name)\n",
    "print(\"Predicted class:\", label_names[pred])\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {label_names[pred]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmuBavvqsswL"
   },
   "source": [
    "## CLIP VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
