{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6488f686-b649-4c5e-878a-29a04e228a81",
   "metadata": {},
   "source": [
    "# GenImages Sample Generator\n",
    "Note: This notebook is designed to be run from a machine where you have access to the *full* GenImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0918b610-f5ff-48b7-8565-051ba3d9e94f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import py7zr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1181b3e8-6a50-4b47-ac0d-8950ca9fb804",
   "metadata": {},
   "source": [
    "## Run Configuration\n",
    "\n",
    "These values should be set per-run.\n",
    "* **runtype** - determines the type of samples produced\n",
    "    * '' - Normal, does not do anything to the images\n",
    "    * 'Cropped' - Creates randomly cropped images\n",
    "    * 'Scaled' - Creates randomly scaled images\n",
    "* **sample_size** - The number of samples per model for each AI and Real\n",
    "    * Note this will go through a 70/15/15 train/validation/test split, which can be configured later.\n",
    "    * So if you set this value to '3000' with all 8 models you will get \n",
    "* **models** - a list of models to include.\n",
    "    * Select which you want from: 'adm','big_gan','glide','midjourney','sd4','sd5','vqdm','wukong'\n",
    "* **scale_type** - The type of scaling used.\n",
    "    * Select From: BICUBIC, BILINEAR, LANCZOS\n",
    "    * Future support (maybe) for RANDOM - doesn't currently work\n",
    "* **cleanup** - When true, removes all non-zipped files after zipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff1e7cd3-8bc9-4707-9a90-ba63039ced36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-Run Configurations go here\n",
    "runtype = 'Scaled' \n",
    "sample_size = 3000\n",
    "models = [\"adm\",\"big_gan\",\"glide\",\"midjourney\",\"sd5\",\"sd4\",\"vqdm\",\"wukong\"]\n",
    "scale_type = 'LANCZOS'\n",
    "cleanup = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44720263-6e7b-4729-9383-c18fbf8b2fb8",
   "metadata": {},
   "source": [
    "## Local Setup \n",
    "This is where you put your file locations - it should only need to be set up once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff3d74f-b191-42ec-b33f-554304d8deb4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Put all your file locations in here\n",
    "\n",
    "# This is where the samples will end up\n",
    "\n",
    "zip_out = \"C:\\\\DL_Temp\"\n",
    "\n",
    "out_train = \"C:\\\\DL_Temp\\\\train\"\n",
    "out_val = \"C:\\\\DL_Temp\\\\validation\"\n",
    "out_test = \"C:\\\\DL_Temp\\\\test\"\n",
    "\n",
    "out_train_ai = out_train + \"\\\\ai\"\n",
    "out_val_ai = out_val + \"\\\\ai\"\n",
    "out_test_ai = out_test + \"\\\\ai\"\n",
    "\n",
    "out_train_real = out_train + \"\\\\real\"\n",
    "out_val_real = out_val + \"\\\\real\"\n",
    "out_test_real = out_test + \"\\\\real\"\n",
    "\n",
    "file_loc = {}\n",
    "\n",
    "# Locations for files - AI \n",
    "file_loc[\"adm_ai\"] = \"D:\\\\ADM\\\\imagenet_ai_0508_adm\\\\train\\\\ai\"\n",
    "file_loc[\"big_gan_ai\"] = \"D:\\\\BigGAN\\\\imagenet_ai_0419_biggan\\\\train\\\\ai\"\n",
    "file_loc[\"glide_ai\"] = \"D:\\\\Glide\\\\imagenet_glide\\\\train\\\\ai\"\n",
    "file_loc[\"midjourney_ai\"] = \"D:\\\\midjourney\\\\imagenet_midjourney\\\\train\\\\ai\"\n",
    "file_loc[\"sd5_ai\"] = \"D:\\\\Stable_Diffusionv5\\\\imagenet_ai_0424_sdv5\\\\train\\\\ai\"\n",
    "file_loc[\"sd4_ai\"] = \"D:\\\\Stable_Diffusionv4\\\\imagenet_ai_0419_sdv4\\\\train\\\\ai\"\n",
    "file_loc[\"vqdm_ai\"] = \"D:\\\\VQDM\\\\imagenet_ai_0419_vqdm\\\\train\\\\ai\"\n",
    "file_loc[\"wukong_ai\"] = \"D:\\\\WuKong\\\\imagenet_ai_0424_wukong\\\\train\\\\ai\"\n",
    "\n",
    "# Locations for files - Real \n",
    "file_loc[\"adm_real\"] = \"D:\\\\ADM\\\\imagenet_ai_0508_adm\\\\train\\\\nature\"\n",
    "file_loc[\"big_gan_real\"] = \"D:\\\\BigGAN\\\\imagenet_ai_0419_biggan\\\\train\\\\nature\"\n",
    "file_loc[\"glide_real\"] = \"D:\\\\Glide\\\\imagenet_glide\\\\train\\\\nature\"\n",
    "file_loc[\"midjourney_real\"] = \"D:\\\\midjourney\\\\imagenet_midjourney\\\\train\\\\nature\"\n",
    "file_loc[\"sd5_real\"] = \"D:\\\\Stable_Diffusionv5\\\\imagenet_ai_0424_sdv5\\\\train\\\\nature\"\n",
    "file_loc[\"sd4_real\"] = \"D:\\\\Stable_Diffusionv4\\\\imagenet_ai_0419_sdv4\\\\train\\\\nature\"\n",
    "file_loc[\"vqdm_real\"] = \"D:\\\\VQDM\\\\imagenet_ai_0419_vqdm\\\\train\\\\nature\"\n",
    "file_loc[\"wukong_real\"] = \"D:\\\\WuKong\\\\imagenet_ai_0424_wukong\\\\train\\\\nature\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b716b93-0cee-4ac6-ac20-edff5f164c44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Useful Function Library \n",
    "\n",
    "* create_image_sample_list(source_dir, sample_size, *...others*) -- creates a file with a train/validation/test split, defaults to 70/15/15 \n",
    "* copy_images_from_list(list_file_path, target_dir) -- actually moves files from the directory over to somewhere to pick up the sample and zip it up\n",
    "* delete_all_files(folder) - Deletes all files in a folder - leaves folder\n",
    "* delete_txt_files(folder) - Deletes all text files in a folder\n",
    "* delete_folder(folder) - Deletes everything, including the folder itself\n",
    "* convert_png_to_jpg(folder, subfolder, quality=90) - Converts a folder of pngs to jpgs (used for AI images)\n",
    "* random_crops (input_folder, archive_folder='archive', crops_per_image=1, min_scale=.5, max_scale=.9, seed=42) - Creates a number of randomly cropped images from each image in a folder\n",
    "* random_scale (input_folder, archive_folder='archive',rescale='LANCZOS', min_scale=.5, max_scale=1.5, seed=42) - creates a number of randomly scaled images from each image in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c8a836-bb4d-4c9b-b06a-b9e9dd992579",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create Sample Lists\n",
    "def create_image_sample_list(\n",
    "     source_dir,\n",
    "    sample_size,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    output_prefix=\"dataset\",\n",
    "    extensions={\".jpg\", \".jpeg\", \".png\", \".webp\"},\n",
    "    seed=42\n",
    "):  \n",
    "    all_images = []\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for f in files:\n",
    "            if os.path.splitext(f.lower())[1] in extensions:\n",
    "                all_images.append(os.path.join(root, f))\n",
    "\n",
    "    if not all_images:\n",
    "        raise ValueError(f\"No image files in: {source_dir}\")\n",
    "\n",
    "    ## Make the sample\n",
    "    n_available = len(all_images)\n",
    "    actual_sample_size = min(sample_size, n_available)\n",
    "\n",
    "    random.seed(seed) \n",
    "    sampled_images = random.sample(all_images, actual_sample_size)\n",
    "\n",
    "    #  Split sampled images into train / val / test \n",
    "    random.shuffle(sampled_images)  # extra shuffle for good measure\n",
    "\n",
    "    n_total = len(sampled_images)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val   = int(n_total * val_ratio)\n",
    "    n_test  = n_total - n_train - n_val  # ensures all are used\n",
    "\n",
    "    train_list = sampled_images[:n_train]\n",
    "    val_list   = sampled_images[n_train:n_train + n_val]\n",
    "    test_list  = sampled_images[n_train + n_val:]\n",
    "\n",
    "    #  Write helper  \n",
    "    def write_list(paths, filepath):\n",
    "        with open(filepath, \"w\") as f:\n",
    "            for p in paths:\n",
    "                f.write(p + \"\\n\")\n",
    "\n",
    "    # Output filenames  \n",
    "    train_file = f\"{output_prefix}_train.txt\"\n",
    "    val_file   = f\"{output_prefix}_val.txt\"\n",
    "    test_file  = f\"{output_prefix}_test.txt\"\n",
    "\n",
    "    #   Write files  \n",
    "    write_list(train_list, train_file)\n",
    "    write_list(val_list, val_file)\n",
    "    write_list(test_list, test_file)\n",
    "\n",
    "    print(f\"Found {n_available} images in total.\")\n",
    "    print(f\"Sampled {n_total} images (requested {sample_size}).\")\n",
    "    print(f\"Train: {len(train_list)} → {train_file}\")\n",
    "    print(f\"Val:   {len(val_list)} → {val_file}\")\n",
    "    print(f\"Test:  {len(test_list)} → {test_file}\")\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8527099c-999f-414b-be5b-5dcc2f77b3cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Get Files From List\n",
    "def copy_images_from_list(list_file_path, target_dir):  \n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    " \n",
    "    with open(list_file_path, \"r\") as f:\n",
    "        image_paths = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        if os.path.isfile(img_path):\n",
    "            shutil.copy(img_path, target_dir)\n",
    "        else:\n",
    "            print(f\"File not found -> {img_path}\")\n",
    "\n",
    "    print(f\"Copied {len(image_paths)} files into {target_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1290048-731e-4523-b917-0bd6299cb3f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# File Management Helpers\n",
    "def delete_all_files(folder):\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            try:\n",
    "                os.remove(os.path.join(root, f))\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {f}: {e}\")\n",
    "\n",
    "def delete_txt_files(folder):\n",
    "    for f in os.listdir(folder):\n",
    "        path = os.path.join(folder, f)\n",
    "        if os.path.isfile(path) and f.lower().endswith(\".txt\"):\n",
    "            os.remove(path)\n",
    "    print(f\"Deleted all text files in: {folder}\")\n",
    "            \n",
    "def delete_folder(folder):\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"Deleted folder: {folder}\")\n",
    "    else:\n",
    "        print(f\"Folder not found: {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "867fe134-f893-4fe1-b282-ef101cf84d22",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert png to jpg\n",
    "def convert_png_to_jpg(folder, subfolder=\"original_pngs\", quality=95): \n",
    "    # Create subfolder for PNG backups\n",
    "    move_path = os.path.join(folder, subfolder)\n",
    "    os.makedirs(move_path, exist_ok=True)\n",
    "\n",
    "    counter = 0\n",
    "    for f in os.listdir(folder):\n",
    "        if f.lower().endswith(\".png\"):\n",
    "            png_path = os.path.join(folder, f)\n",
    "            jpg_name = f.rsplit(\".\", 1)[0] + \".jpg\"\n",
    "            jpg_path = os.path.join(folder, jpg_name)\n",
    "\n",
    "            # Convert PNG → JPG\n",
    "            img = Image.open(png_path).convert(\"RGB\")\n",
    "            img.save(jpg_path, \"JPEG\", quality=quality)\n",
    "            \n",
    "            # Move original PNG to the subfolder\n",
    "            shutil.move(png_path, os.path.join(move_path, f))\n",
    "            counter = counter + 1\n",
    "    print(\"Converted \", counter, \" images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1b3233-8037-436a-b8e4-b77b1cbb7551",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function for randomly cropping images \n",
    "def random_crops(\n",
    "    input_folder,\n",
    "    archive_folder = \"archive\", # naming to not overlap with convert_png_to_jpg\n",
    "    crops_per_image=1,\n",
    "    min_scale=0.5,\n",
    "    max_scale=0.9,\n",
    "    seed=42\n",
    "): \n",
    "    archive_path = os.path.join(input_folder, archive_folder)\n",
    "    os.makedirs(archive_path, exist_ok=True)\n",
    "    \n",
    "    random.seed(seed)\n",
    "    img_counter = 0\n",
    "\n",
    "    print(f\"Starting {input_folder}.\")\n",
    "\n",
    "    files = [f for f in os.listdir(input_folder)\n",
    "             if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".webp\"))\n",
    "             and f != archive_folder]\n",
    "    \n",
    "    for filename in files: \n",
    "\n",
    "        try:\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            img = Image.open(img_path)\n",
    "    \n",
    "            w, h = img.size \n",
    "    \n",
    "            for i in range(crops_per_image):\n",
    "                # Choose a random crop size between min_scale and max_scale for each direction\n",
    "                scale_w = random.uniform(min_scale, max_scale)\n",
    "                scale_h = random.uniform(min_scale, max_scale)\n",
    "                crop_size_w = int(w * scale_w)\n",
    "                crop_size_h = int(h * scale_h)\n",
    "    \n",
    "                # Max for Upper Left Corner\n",
    "                max_x = w - crop_size_w\n",
    "                max_y = h - crop_size_h\n",
    "     \n",
    "                x1 = random.randint(0, max_x)\n",
    "                y1 = random.randint(0, max_y)\n",
    "                x2 = x1 + crop_size_w\n",
    "                y2 = y1 + crop_size_h\n",
    "    \n",
    "                cropped = img.crop((x1, y1, x2, y2))\n",
    "    \n",
    "                # Save output\n",
    "                base = os.path.splitext(filename)[0]\n",
    "                out_name = f\"{base}_crop{i+1}.jpg\"\n",
    "                out_path = os.path.join(input_folder, out_name)\n",
    "    \n",
    "                cropped.save(out_path, \"JPEG\", quality=95)\n",
    "                \n",
    "            img_counter = img_counter + 1    \n",
    "            shutil.move(img_path, os.path.join(archive_path, filename))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename} → deleting it. Reason: {e}\")\n",
    "            try:\n",
    "                os.remove(img_path)\n",
    "            except Exception:\n",
    "                print(f\"Could not delete {img_path}, skipping.\")\n",
    "            continue  # move to the next file\n",
    "\n",
    "    print(f\"Processed {img_counter} images in {input_folder}, created {crops_per_image} samples each.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9316a26b-be8e-4e93-b629-7f5e1e86f4d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Function for randomly scaling images\n",
    "def random_scale(\n",
    "    input_folder,\n",
    "    archive_folder=\"archive\",\n",
    "    rescale='LANCZOS', # BICUBIC, BILINEAR, LANCZOS, RANDOM\n",
    "    min_scale=0.5,\n",
    "    max_scale=1.5,\n",
    "    seed=42\n",
    "): \n",
    " \n",
    " \n",
    "    archive_path = os.path.join(input_folder, archive_folder)\n",
    "    os.makedirs(archive_path, exist_ok=True)\n",
    "\n",
    "    random.seed(seed)\n",
    "    img_counter = 0\n",
    "\n",
    "    print(f\"Processing folder: {input_folder}\")\n",
    "\n",
    "    # Snapshot of files so we don't pick up newly written files\n",
    "    files = [\n",
    "        f for f in os.listdir(input_folder)\n",
    "        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".webp\"))\n",
    "        and f != archive_folder\n",
    "    ]\n",
    "\n",
    "    for filename in files:\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Try to open the image\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            w, h = img.size\n",
    "\n",
    "            # Pick a random scale size\n",
    "            scale = random.uniform(min_scale, max_scale)\n",
    "            new_w = max(1, int(w * scale))\n",
    "            new_h = max(1, int(h * scale))\n",
    "\n",
    "            # Resize with a filter\n",
    "            if rescale == 'BICUBIC':\n",
    "                resized = img.resize((new_w, new_h), Image.BICUBIC)\n",
    "            elif rescale == 'BILINEAR':\n",
    "                resized = img.resize((new_w, new_h), Image.BILINEAR)\n",
    "            else:\n",
    "                resized = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "            \n",
    " \n",
    "            archived_file_path = os.path.join(archive_path, filename)\n",
    "        \n",
    "            try:\n",
    "                shutil.move(img_path, archived_file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not archive {filename}, deleting instead. Reason: {e}\")\n",
    "                try:\n",
    "                    os.remove(img_path)\n",
    "                except Exception:\n",
    "                    print(f\"Could not delete {img_path}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Save scaled image back to original location (same name)\n",
    "            base = os.path.splitext(filename)[0]\n",
    "            out_name = f\"{base}_resize.jpg\"\n",
    "            out_path = os.path.join(input_folder, out_name)\n",
    "    \n",
    "            resized.save(out_path, \"JPEG\", quality=95)\n",
    "            \n",
    "            img_counter += 1 \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename} → deleting it. Reason: {e}\")\n",
    "            try:\n",
    "                os.remove(img_path)\n",
    "            except Exception:\n",
    "                print(f\"Could not delete {img_path}, skipping.\")\n",
    "            continue  # move to the next file\n",
    "\n",
    "    print(f\"Processed {img_counter} images in {input_folder}, created {crops_per_image} samples each.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4d677d-ea02-4e01-8e36-a7b07ce5c691",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Function for randomly scaling images\n",
    "def random_scale(\n",
    "    input_folder,\n",
    "    archive_folder=\"archive\",\n",
    "    rescale='LANCZOS', # BICUBIC, BILINEAR, LANCZOS, RANDOM\n",
    "    min_scale=0.5,\n",
    "    max_scale=1.5,\n",
    "    seed=42\n",
    "): \n",
    " \n",
    " \n",
    "    archive_path = os.path.join(input_folder, archive_folder)\n",
    "    os.makedirs(archive_path, exist_ok=True)\n",
    "\n",
    "    random.seed(seed)\n",
    "    img_counter = 0\n",
    "\n",
    "    print(f\"Processing folder: {input_folder}\")\n",
    "\n",
    "    # Snapshot of files so we don't pick up newly written files\n",
    "    files = [\n",
    "        f for f in os.listdir(input_folder)\n",
    "        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".webp\"))\n",
    "        and f != archive_folder\n",
    "    ]\n",
    "\n",
    "    for filename in files:\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Try to open the image\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            w, h = img.size\n",
    "\n",
    "            # Pick a random scale size\n",
    "            scale = random.uniform(min_scale, max_scale)\n",
    "            new_w = max(1, int(w * scale))\n",
    "            new_h = max(1, int(h * scale))\n",
    "\n",
    "            # Resize with a filter\n",
    "            if rescale == 'BICUBIC':\n",
    "                resized = img.resize((new_w, new_h), Image.BICUBIC)\n",
    "            elif rescale == 'BILINEAR':\n",
    "                resized = img.resize((new_w, new_h), Image.BILINEAR)\n",
    "            else:\n",
    "                resized = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "            \n",
    " \n",
    "            archived_file_path = os.path.join(archive_path, filename)\n",
    "        \n",
    "            try:\n",
    "                shutil.move(img_path, archived_file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not archive {filename}, deleting instead. Reason: {e}\")\n",
    "                try:\n",
    "                    os.remove(img_path)\n",
    "                except Exception:\n",
    "                    print(f\"Could not delete {img_path}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Save scaled image back to original location (same name)\n",
    "            base = os.path.splitext(filename)[0]\n",
    "            out_name = f\"{base}_resize.jpg\"\n",
    "            out_path = os.path.join(input_folder, out_name)\n",
    "    \n",
    "            resized.save(out_path, \"JPEG\", quality=95)\n",
    "            \n",
    "            img_counter += 1 \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename} → deleting it. Reason: {e}\")\n",
    "            try:\n",
    "                os.remove(img_path)\n",
    "            except Exception:\n",
    "                print(f\"Could not delete {img_path}, skipping.\")\n",
    "            continue  # move to the next file\n",
    "\n",
    "    print(f\"Processed {img_counter} images in {input_folder}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a3e1f6-8b98-4766-97e6-91d4d01950ff",
   "metadata": {},
   "source": [
    "## Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6d8d71-e3d5-4d07-8bce-713415de51b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted all text files in: .\n"
     ]
    }
   ],
   "source": [
    "# Deletion Script to run at the beginning of start\n",
    "\n",
    "delete_all_files(out_train_ai)\n",
    "delete_all_files(out_test_ai)\n",
    "delete_all_files(out_val_ai)\n",
    "\n",
    "delete_all_files(out_train_real)\n",
    "delete_all_files(out_test_real)\n",
    "delete_all_files(out_val_real)\n",
    "\n",
    "delete_txt_files(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97de7f26-a57e-495f-8f3a-06ffefa42264",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Starting adm ----\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → adm_ai_train.txt\n",
      "Val:   450 → adm_ai_val.txt\n",
      "Test:  450 → adm_ai_test.txt\n",
      "Found 157453 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → adm_real_train.txt\n",
      "Val:   450 → adm_real_val.txt\n",
      "Test:  450 → adm_real_test.txt\n",
      "---- Starting big_gan ----\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → big_gan_ai_train.txt\n",
      "Val:   450 → big_gan_ai_val.txt\n",
      "Test:  450 → big_gan_ai_test.txt\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → big_gan_real_train.txt\n",
      "Val:   450 → big_gan_real_val.txt\n",
      "Test:  450 → big_gan_real_test.txt\n",
      "---- Starting glide ----\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → glide_ai_train.txt\n",
      "Val:   450 → glide_ai_val.txt\n",
      "Test:  450 → glide_ai_test.txt\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → glide_real_train.txt\n",
      "Val:   450 → glide_real_val.txt\n",
      "Test:  450 → glide_real_test.txt\n",
      "---- Starting midjourney ----\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → midjourney_ai_train.txt\n",
      "Val:   450 → midjourney_ai_val.txt\n",
      "Test:  450 → midjourney_ai_test.txt\n",
      "Found 161701 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → midjourney_real_train.txt\n",
      "Val:   450 → midjourney_real_val.txt\n",
      "Test:  450 → midjourney_real_test.txt\n",
      "---- Starting sd5 ----\n",
      "Found 166000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → sd5_ai_train.txt\n",
      "Val:   450 → sd5_ai_val.txt\n",
      "Test:  450 → sd5_ai_test.txt\n",
      "Found 153274 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → sd5_real_train.txt\n",
      "Val:   450 → sd5_real_val.txt\n",
      "Test:  450 → sd5_real_test.txt\n",
      "---- Starting sd4 ----\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → sd4_ai_train.txt\n",
      "Val:   450 → sd4_ai_val.txt\n",
      "Test:  450 → sd4_ai_test.txt\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → sd4_real_train.txt\n",
      "Val:   450 → sd4_real_val.txt\n",
      "Test:  450 → sd4_real_test.txt\n",
      "---- Starting vqdm ----\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → vqdm_ai_train.txt\n",
      "Val:   450 → vqdm_ai_val.txt\n",
      "Test:  450 → vqdm_ai_test.txt\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → vqdm_real_train.txt\n",
      "Val:   450 → vqdm_real_val.txt\n",
      "Test:  450 → vqdm_real_test.txt\n",
      "---- Starting wukong ----\n",
      "Found 162000 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → wukong_ai_train.txt\n",
      "Val:   450 → wukong_ai_val.txt\n",
      "Test:  450 → wukong_ai_test.txt\n",
      "Found 160739 images in total.\n",
      "Sampled 3000 images (requested 3000).\n",
      "Train: 2100 → wukong_real_train.txt\n",
      "Val:   450 → wukong_real_val.txt\n",
      "Test:  450 → wukong_real_test.txt\n"
     ]
    }
   ],
   "source": [
    "# Make Sample File List\n",
    "for m in models:\n",
    "    print(\"---- Starting \" + m + \" ----\")\n",
    "    ai_source = m + \"_ai\"\n",
    "    real_source = m + \"_real\"\n",
    "    \n",
    "    create_image_sample_list(source_dir=file_loc[ai_source], sample_size=sample_size, output_prefix=ai_source) \n",
    "    create_image_sample_list(source_dir=file_loc[real_source], sample_size=sample_size, output_prefix=real_source) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbd0d73e-268a-4380-acb1-5987de5bd5ca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Starting adm ----\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\ai.\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\real.\n",
      "---- Starting big_gan ----\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\ai.\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\real.\n",
      "---- Starting glide ----\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\ai.\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\real.\n",
      "---- Starting midjourney ----\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\ai.\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\real.\n",
      "---- Starting sd5 ----\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\ai.\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\real.\n",
      "---- Starting sd4 ----\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\ai.\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\real.\n",
      "---- Starting vqdm ----\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\ai.\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\real.\n",
      "---- Starting wukong ----\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\ai.\n",
      "Copied 2100 files into C:\\DL_Temp\\train\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\test\\real.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\ai.\n",
      "Copied 450 files into C:\\DL_Temp\\validation\\real.\n"
     ]
    }
   ],
   "source": [
    "# Copy Files\n",
    "for m in models:\n",
    "    print(\"---- Starting \" + m + \" ----\")\n",
    "    ai_file = m + \"_ai\"\n",
    "    real_file = m + \"_real\"\n",
    "     \n",
    "    copy_images_from_list(ai_file + \"_train.txt\", out_train_ai)\n",
    "    copy_images_from_list(real_file + \"_train.txt\", out_train_real)\n",
    "    copy_images_from_list(ai_file + \"_test.txt\", out_test_ai)\n",
    "    copy_images_from_list(real_file + \"_test.txt\", out_test_real)\n",
    "    copy_images_from_list(ai_file + \"_val.txt\", out_val_ai)\n",
    "    copy_images_from_list(real_file + \"_val.txt\", out_val_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921585b2-fc7d-454a-b1c4-ae1183a95860",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted  3600  images\n",
      "Converted  3600  images\n",
      "Converted  16800  images\n"
     ]
    }
   ],
   "source": [
    "# Convert PNG to JPG\n",
    "convert_png_to_jpg(out_test_ai,\"original\")\n",
    "convert_png_to_jpg(out_val_ai,\"original\")\n",
    "convert_png_to_jpg(out_train_ai,\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74dee22e-834a-4e38-a22b-b95608d41c51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted folder: C:\\DL_Temp\\test\\ai\\original\n",
      "Deleted folder: C:\\DL_Temp\\validation\\ai\\original\n",
      "Deleted folder: C:\\DL_Temp\\train\\ai\\original\n"
     ]
    }
   ],
   "source": [
    "# Delete Original PNGs\n",
    "delete_folder(out_test_ai + \"\\\\original\")\n",
    "delete_folder(out_val_ai + \"\\\\original\")\n",
    "delete_folder(out_train_ai + \"\\\\original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31582a85-47cc-4107-a39e-01136ab51fb0",
   "metadata": {},
   "source": [
    "## Perform Cropping/Resizing etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab85f8c0-ff84-499c-aa6f-73b9dba19d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Cropping - Crop Images\n",
    "if runtype == 'Cropped': # Optional - Create Crops \n",
    "    random_crops(out_test_ai)\n",
    "    random_crops(out_test_real)\n",
    "    random_crops(out_val_ai)\n",
    "    random_crops(out_val_real)\n",
    "    random_crops(out_train_ai)\n",
    "    random_crops(out_train_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d265f62c-ff10-4d5d-8a9d-df948dfbbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Cropping - Delete Archives\n",
    "if runtype == 'Cropped': # Delete Archives before Zipping\n",
    "    delete_folder(out_test_ai + \"\\\\archive\")\n",
    "    delete_folder(out_val_ai + \"\\\\archive\")\n",
    "    delete_folder(out_train_ai + \"\\\\archive\")\n",
    "    \n",
    "    delete_folder(out_test_real + \"\\\\archive\")\n",
    "    delete_folder(out_val_real + \"\\\\archive\")\n",
    "    delete_folder(out_train_real + \"\\\\archive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f66fcb4-6f4d-494f-822b-64b4066f503d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: C:\\DL_Temp\\test\\ai\n",
      "Processed 3600 images in C:\\DL_Temp\\test\\ai.\n",
      "Processing folder: C:\\DL_Temp\\test\\real\n",
      "Error reading n03447721_40894.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03447721_40894.JPEG'\n",
      "Error reading n03450230_1303.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03450230_1303.JPEG'\n",
      "Error reading n03452741_20019.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03452741_20019.JPEG'\n",
      "Error reading n03457902_14560.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03457902_14560.JPEG'\n",
      "Error reading n03476684_9581.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03476684_9581.JPEG'\n",
      "Error reading n03482405_21043.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03482405_21043.JPEG'\n",
      "Error reading n03483316_23597.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03483316_23597.JPEG'\n",
      "Error reading n03485794_25767.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03485794_25767.JPEG'\n",
      "Error reading n03485794_372.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03485794_372.JPEG'\n",
      "Error reading n03494278_39765.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03494278_39765.JPEG'\n",
      "Error reading n03494278_43731.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03494278_43731.JPEG'\n",
      "Error reading n03495258_4511.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03495258_4511.JPEG'\n",
      "Error reading n03529860_11959.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\test\\\\real\\\\n03529860_11959.JPEG'\n",
      "Processed 3587 images in C:\\DL_Temp\\test\\real.\n",
      "Processing folder: C:\\DL_Temp\\validation\\ai\n",
      "Processed 3600 images in C:\\DL_Temp\\validation\\ai.\n",
      "Processing folder: C:\\DL_Temp\\validation\\real\n",
      "Error reading n03445777_7086.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\validation\\\\real\\\\n03445777_7086.JPEG'\n",
      "Error reading n03467068_6155.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\validation\\\\real\\\\n03467068_6155.JPEG'\n",
      "Error reading n03481172_13074.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\validation\\\\real\\\\n03481172_13074.JPEG'\n",
      "Error reading n03482405_3063.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\validation\\\\real\\\\n03482405_3063.JPEG'\n",
      "Error reading n03483316_3688.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\validation\\\\real\\\\n03483316_3688.JPEG'\n",
      "Processed 3595 images in C:\\DL_Temp\\validation\\real.\n",
      "Processing folder: C:\\DL_Temp\\train\\ai\n",
      "Processed 16800 images in C:\\DL_Temp\\train\\ai.\n",
      "Processing folder: C:\\DL_Temp\\train\\real\n",
      "Error reading n03445777_4042.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03445777_4042.JPEG'\n",
      "Error reading n03445777_7147.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03445777_7147.JPEG'\n",
      "Error reading n03445924_24291.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03445924_24291.JPEG'\n",
      "Error reading n03445924_4872.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03445924_4872.JPEG'\n",
      "Error reading n03445924_8541.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03445924_8541.JPEG'\n",
      "Error reading n03445924_872.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03445924_872.JPEG'\n",
      "Error reading n03447447_14741.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03447447_14741.JPEG'\n",
      "Error reading n03447447_8882.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03447447_8882.JPEG'\n",
      "Error reading n03447721_15705.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03447721_15705.JPEG'\n",
      "Error reading n03447721_16338.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03447721_16338.JPEG'\n",
      "Error reading n03447721_7387.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03447721_7387.JPEG'\n",
      "Error reading n03450230_12597.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03450230_12597.JPEG'\n",
      "Error reading n03450230_1661.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03450230_1661.JPEG'\n",
      "Error reading n03450230_3139.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03450230_3139.JPEG'\n",
      "Error reading n03450230_7148.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03450230_7148.JPEG'\n",
      "Error reading n03452741_11588.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03452741_11588.JPEG'\n",
      "Error reading n03452741_2910.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03452741_2910.JPEG'\n",
      "Error reading n03452741_6659.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03452741_6659.JPEG'\n",
      "Error reading n03459775_18690.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03459775_18690.JPEG'\n",
      "Error reading n03459775_5401.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03459775_5401.JPEG'\n",
      "Error reading n03461385_35622.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03461385_35622.JPEG'\n",
      "Error reading n03461385_52244.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03461385_52244.JPEG'\n",
      "Error reading n03461385_55558.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03461385_55558.JPEG'\n",
      "Error reading n03467068_12179.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03467068_12179.JPEG'\n",
      "Error reading n03467068_13403.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03467068_13403.JPEG'\n",
      "Error reading n03476684_11841.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03476684_11841.JPEG'\n",
      "Error reading n03476684_19139.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03476684_19139.JPEG'\n",
      "Error reading n03478589_16121.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03478589_16121.JPEG'\n",
      "Error reading n03478589_17548.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03478589_17548.JPEG'\n",
      "Error reading n03478589_4559.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03478589_4559.JPEG'\n",
      "Error reading n03478589_8080.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03478589_8080.JPEG'\n",
      "Error reading n03481172_9568.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03481172_9568.JPEG'\n",
      "Error reading n03482405_29635.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03482405_29635.JPEG'\n",
      "Error reading n03482405_5083.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03482405_5083.JPEG'\n",
      "Error reading n03482405_6412.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03482405_6412.JPEG'\n",
      "Error reading n03483316_46638.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03483316_46638.JPEG'\n",
      "Error reading n03483316_5283.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03483316_5283.JPEG'\n",
      "Error reading n03485794_11425.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03485794_11425.JPEG'\n",
      "Error reading n03485794_14230.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03485794_14230.JPEG'\n",
      "Error reading n03485794_36524.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03485794_36524.JPEG'\n",
      "Error reading n03492542_10748.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03492542_10748.JPEG'\n",
      "Error reading n03492542_25135.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03492542_25135.JPEG'\n",
      "Error reading n03492542_32611.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03492542_32611.JPEG'\n",
      "Error reading n03495258_12821.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03495258_12821.JPEG'\n",
      "Error reading n03495258_24377.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03495258_24377.JPEG'\n",
      "Error reading n03495258_4646.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03495258_4646.JPEG'\n",
      "Error reading n03495258_9181.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03495258_9181.JPEG'\n",
      "Error reading n03496892_23430.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03496892_23430.JPEG'\n",
      "Error reading n03496892_5793.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03496892_5793.JPEG'\n",
      "Error reading n03527444_17925.JPEG → deleting it. Reason: cannot identify image file 'C:\\\\DL_Temp\\\\train\\\\real\\\\n03527444_17925.JPEG'\n",
      "Processed 16750 images in C:\\DL_Temp\\train\\real.\n"
     ]
    }
   ],
   "source": [
    "# If Scaling - Scale Images\n",
    "if runtype == 'Scaled':  \n",
    "    random_scale(out_test_ai)\n",
    "    random_scale(out_test_real)\n",
    "    random_scale(out_val_ai)\n",
    "    random_scale(out_val_real)\n",
    "    random_scale(out_train_ai)\n",
    "    random_scale(out_train_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28b98bb3-3817-40fb-a201-a7cb743dde20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted folder: C:\\DL_Temp\\test\\ai\\archive\n",
      "Deleted folder: C:\\DL_Temp\\validation\\ai\\archive\n",
      "Deleted folder: C:\\DL_Temp\\train\\ai\\archive\n",
      "Deleted folder: C:\\DL_Temp\\test\\real\\archive\n",
      "Deleted folder: C:\\DL_Temp\\validation\\real\\archive\n",
      "Deleted folder: C:\\DL_Temp\\train\\real\\archive\n"
     ]
    }
   ],
   "source": [
    "# If Scaled - Delete Archives\n",
    "if runtype == 'Scaled': # Delete Archives before Zipping\n",
    "    delete_folder(out_test_ai + \"\\\\archive\")\n",
    "    delete_folder(out_val_ai + \"\\\\archive\")\n",
    "    delete_folder(out_train_ai + \"\\\\archive\")\n",
    "    \n",
    "    delete_folder(out_test_real + \"\\\\archive\")\n",
    "    delete_folder(out_val_real + \"\\\\archive\")\n",
    "    delete_folder(out_train_real + \"\\\\archive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44505de2-0583-4dc8-8b4e-ce93811282bc",
   "metadata": {},
   "source": [
    "## Zipping into a nice package\n",
    "Remember to save these before you run next time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8940bc2b-fbe1-4d19-81c2-cd85b8a3f37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Zipping Test!\n",
      "Finished Zipping Validation!\n",
      "Finished Zipping Train!\n"
     ]
    }
   ],
   "source": [
    "# Zip Up Results \n",
    "\n",
    "with py7zr.SevenZipFile(zip_out + '\\\\test.7z', mode='w') as z: \n",
    "        z.writeall(out_test_ai)\n",
    "        z.writeall(out_test_real)\n",
    "print(\"Finished Zipping Test!\") \n",
    "\n",
    "with py7zr.SevenZipFile(zip_out + '\\\\validation.7z', mode='w') as z: \n",
    "        z.writeall(out_val_ai)\n",
    "        z.writeall(out_val_real)\n",
    "print(\"Finished Zipping Validation!\")\n",
    "\n",
    "with py7zr.SevenZipFile(zip_out + '\\\\train.7z', mode='w') as z: \n",
    "        z.writeall(out_train_ai)\n",
    "        z.writeall(out_train_real)\n",
    "print(\"Finished Zipping Train!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb8c37-045a-4d69-9c12-5d7aa6bda2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cleanup:\n",
    "    delete_all_files(out_train_ai)\n",
    "    delete_all_files(out_test_ai)\n",
    "    delete_all_files(out_val_ai)\n",
    "\n",
    "    delete_all_files(out_train_real)\n",
    "    delete_all_files(out_test_real)\n",
    "    delete_all_files(out_val_real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
